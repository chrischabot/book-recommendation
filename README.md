# Book Recommendation Engine

*A slightly obsessive attempt to answer the eternal question: "What should I read next?"*

---

You know that feeling. You've just finished an incredible book—the kind that keeps you turning pages until 2 AM, the kind that makes you feel vaguely betrayed when it ends. Now you're staring at your bookshelf (or, let's be honest, your Kindle library of 847 unread titles), paralyzed by indecision. Amazon thinks you want "more books like this," but their suggestions feel like they were generated by someone who read the back cover and gave up.

This project exists because recommendations shouldn't be a black box. It's a personal "reading brain" that actually *understands* your taste—not by tracking your clicks or optimizing for purchases, but by mathematically modeling the relationships between everything you've ever loved (or hated) reading.

## How It Works

At its core, this is a hybrid recommendation engine that combines three different approaches, because books are complicated and humans are worse:

### 1. Semantic Understanding (Neural Embeddings)

Every book in the system gets converted into a 768-dimensional vector using neural language models. These vectors capture the *meaning* of a book—not just keywords, but themes, tone, and style. Think of it as giving each book a mathematical fingerprint.

When you rate a book 5 stars, the system averages your highly-rated books into a "taste vector"—a single point in semantic space that represents *you* as a reader. Recommendations are then just the books closest to that point that you haven't read yet.

### 2. "People Also Read" (Collaborative Filtering via Graph)

The system ingests reading logs and lists from Open Library (millions of them), building a co-occurrence graph. If 10,000 people who read Book A also read Book B, that's a signal. The more readers two books share, the stronger their connection.

This runs on PostgreSQL with `pgvector` for the embeddings and Apache AGE for graph queries, because sometimes you need industrial-strength tools for your weekend project.

### 3. The Boring Stuff (That Actually Matters)

Series detection, author relationships, genre taxonomies, and good old-fashioned popularity scores. Because sometimes you just want to know which Hugo Award winners you haven't read yet.

## Data Sources

This thing is *hungry* for data. It inhales:

- **Open Library**: 18+ million works, complete with subjects, authors, and user reading logs
- **Google Books**: Metadata for coverage of modern and self-published titles
- **Goodreads Export**: Your personal library, ratings, and that enormous to-read list you're never getting through
- **Kindle Data Export**: Actual reading sessions, completion events, and the damning evidence of books you abandoned at 15%
- **Wikidata**: Series information, awards, and external identifiers for cross-referencing

All book data is stored at the "Work" level (the abstract book) rather than "Edition" level (the specific paperback you own), following the FRBR library model. This prevents the system from recommending you five different editions of *Dune*.

## Interesting Facts

- The identifier resolver follows a strict priority chain: `ISBN-13 > ISBN-10 > Google Volume ID > ASIN > Goodreads Work ID > Title+Author`. Fuzzy title matching is a last resort because it's hilariously error-prone.

- The schema is based on the FRBR (Functional Requirements for Bibliographic Records) model used by actual libraries. Works are abstract; editions are manifestations. Your dog-eared paperback of *The Great Gatsby* is an Item-level manifestation of the Work that Fitzgerald probably regretted writing.

- Book covers from Open Library are detected as "missing" by checking if the returned image is a 1×1 transparent pixel. This happens more often than you'd think.

- The system can parse series information from Goodreads title strings like "The Final Empire (Mistborn, #1)" using regex. It handles edge cases like "Oathbringer (Stormlight Archive, The #3)" because apparently some databases store article positions arbitrarily.

- Embeddings are generated locally on Apple Silicon using MLX, because why pay for API calls when you have 128GB of unified memory burning a hole in your laptop?

- The "global popularity score" combines ratings count, average rating, want-to-read counts, and list appearances into a single metric that's been tuned by exactly one person (me) based on vibes.

## Stack

- **Next.js 16** (App Router) — For the UI that lets you pretend this isn't just a glorified database browser
- **PostgreSQL 18** — With `pgvector` for semantic search and `pg_trgm` for fuzzy text matching
- **shadcn/ui + Tailwind** — Because life's too short to write CSS from scratch
- **MLX** — Apple's ML framework for local embedding generation

## Philosophy

Book recommendations are personal. The "best" book for you isn't necessarily the highest-rated or most popular—it's the one that intersects with your particular interests, mood, and reading history in the right way at the right time.

This project doesn't try to be Netflix. It doesn't optimize for engagement or push trending titles. It just tries to find books you might actually love, using every signal available, and lets you see exactly why it made each recommendation.

Is it overkill? Absolutely. But so is having a thousand unread books, and at least this way I feel productive about it.

---

*Built with the conviction that finding your next great read shouldn't require an algorithm with a profit motive.*
